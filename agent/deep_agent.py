"""Deep Agent - MVP ç‰ˆæœ¬ (Vertex AI + LangChain)"""
import logging
# from typing import Dict, Any, Optional
# from pathlib import Path
# from langchain.messages import (
#     AIMessage,
#     AIMessageChunk,
#     HumanMessage,
#     SystemMessage,
# )
from deepagents import create_deep_agent
from agent.models import AnthropicModelProvider
# from simple_config import BaseAgentConfig, get_config
from agent.prompts import get_system_prompt
from deepagents.backends import FilesystemBackend
from agent.chunk_parser import ChunkParser

logger = logging.getLogger(__name__)


class RefactorAgent:
    def __init__(
        self,
        model=None,
        verbose: bool = True,
        stop_check_callback=None,
    ):
        """åˆå§‹åŒ– RefactorAgent

        Args:
            model: LLM æ¨¡å‹å¯¦ä¾‹
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°çš„ chunk è§£æè³‡è¨Š
            stop_check_callback: å¯é¸çš„åœæ­¢æª¢æŸ¥å›èª¿å‡½æ•¸ï¼Œè¿”å› True è¡¨ç¤ºæ‡‰è©²åœæ­¢
        """
        self.model = model
        self.verbose = verbose
        self.root_dir = "/workspace/"
        self.stop_check_callback = stop_check_callback
        self._agent_init()

    def _agent_init(self):
        if not self.model:
            raise ValueError("model is not set")

        self.agent = create_deep_agent(
            model=self.model,
            memory=[
                f"{self.root_dir}/memory/AGENTS.md",
            ],
            tools=[],
            backend=FilesystemBackend(
                root_dir=self.root_dir,
                virtual_mode=True
            ),
            system_prompt=get_system_prompt("default")
        )

    def run(self, user_message: str = "æª¢è¦–æˆ‘çš„å°ˆæ¡ˆè³‡æ–™å¤¾çµæ§‹", event_callback=None):
        """åŸ·è¡Œ Agent ä¸¦ä½¿ç”¨ ChunkParser è§£æä¸²æµè¼¸å‡º

        Args:
            user_message: ä½¿ç”¨è€…è¨Šæ¯
            event_callback: å¯é¸çš„å›èª¿å‡½æ•¸ï¼Œç”¨æ–¼è™•ç†æ¯å€‹è§£æäº‹ä»¶
                          å‡½æ•¸ç°½å: callback(event_type: str, data: dict)
        """
        # åˆå§‹åŒ– ChunkParserï¼ˆå‚³å…¥ callbackï¼‰
        parser = ChunkParser(verbose=self.verbose, event_callback=event_callback)

        print(f"\n{'='*60}", flush=True)
        print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ Agent", flush=True)
        print(f"{'='*60}\n", flush=True)
        print(f"ğŸ“ User Message: {user_message}\n", flush=True)
        print(f"{'â”€'*60}", flush=True)
        print(f"ğŸ’¬ AI Response:\n", flush=True)

        # ä¸²æµåŸ·è¡Œ
        result = self.agent.stream({
            "messages": [
                {"role": "user", "content": user_message}
            ]
        })

        # ä½¿ç”¨ ChunkParser è§£ææ¯å€‹ chunk
        try:
            for chunk in result:
                # æª¢æŸ¥æ˜¯å¦æ‡‰è©²åœæ­¢
                if self.stop_check_callback and self.stop_check_callback():
                    print(f"\n{'='*60}", flush=True)
                    print(f"â¹ï¸  æª¢æ¸¬åˆ°åœæ­¢ä¿¡è™Ÿï¼Œä¸­æ–· Agent åŸ·è¡Œ", flush=True)
                    print(f"{'='*60}\n", flush=True)
                    raise KeyboardInterrupt("Agent stopped by user")

                parser.parse(chunk)
        except KeyboardInterrupt:
            print(f"\n{'='*60}", flush=True)
            print(f"â¹ï¸  Agent åŸ·è¡Œå·²è¢«ä¸­æ–·", flush=True)
            print(f"{'='*60}\n", flush=True)
            raise

        # é¡¯ç¤ºç¸½çµ
        parser.print_summary()


if __name__ == "__main__":
    # åˆå§‹åŒ– LLM (æ ¹æ“šç’°å¢ƒè®Šæ•¸ LLM_PROVIDER è‡ªå‹•é¸æ“‡)
    provider = AnthropicModelProvider()
    model = provider.get_model()

    # å‰µå»º Agent (verbose=True æœƒé¡¯ç¤ºè©³ç´°çš„ token usage, tool calls ç­‰è³‡è¨Š)
    agent = RefactorAgent(model, verbose=True)
    message = """
    æª¢è¦–æˆ‘çš„è³‡æ–™å¤¾çµæ§‹ï¼Œä¸¦æ•´ç†ä¸€å€‹å°‡æ­¤å°ˆæ¡ˆé‡æ§‹æˆ typescript çš„è¨ˆç•«ï¼Œä¸¦å°‡æª”æ¡ˆå¯«å…¥ ./memory/plan.md æª”æ¡ˆ
    """
    # åŸ·è¡Œ Agent
    agent.run(user_message=message)
